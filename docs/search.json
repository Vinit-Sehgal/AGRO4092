[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Spatial Analysis & Visualization",
    "section": "",
    "text": "1 Introduction\nStatistical computing is essential for scientific inquiry, discovery, and storytelling. As the availability of dataset and access to computing has significantly increased over the recent years, the scope of scientific inquiry is restricted, only, by the imagination of the inquirer.\n\n“Scientific inquiry starts with observation. The more one can see, the more one can investigate” — Martin Chalfie\n\nHowever, analysis of large-scale geospatial data (regional- to global scale at high spatial and temporal resolution) can be computationally expensive and time-consuming, especially when working with multiple formats and sources of data. R- a higher-level programming language, provides a powerful computational alternative to popular Geographic Information System (GIS) software to organize, analyze and visualize geospatial datasets. R enjoys a vast collection of open-source libraries for GIS-type operations and proven statistical analysis and data visualization capabilities.\nIn this course, we equip ourselves with hands-on knowledge of accessing, analyzing, and visualizing open-source satellite remote-sensing and geospatial datasets for hydrological, agricultural, and climatological studies within the R environment. The objective of this course is to learn R for:\n\nAnalyzing geospatial datasets (raster and vector),\nPerforming statistical analysis for each feature/ layer, and,\nMapping and visualizing spatial datasets.\n\nThe course will include the latest R tools for working with global Earth-observation datasets, such as from NASA’s MODIS and SMAP satellites. Basic operations of geospatial analysis such as (re)projection, (re)sampling, summary statistics, merge/join, and (re)shape will be covered. The students will be introduced to structured/layered spatial datasets such as NetCDF and HDF formats used in climate modeling. Special emphasis will be placed on applying available out-of-the-box parallel computing techniques for geospatial analysis available in R.\nWe will first start with a refresher of basic R programming in Module 1. In Module 2 and 3, we will explore spatial data visualization, before we learn about large-scale application of parallel computing for geospatial analysis.\nPurpose of this document:\nThis resource will serve as a dynamic class note, where students can access detailed concepts, codes and exercises related to this class. Notes will be updated regularly as the class progresses with up-to-date material and upcoming assignments.\n\n\n\n\nAcknowledgement:\n\n\nWe thank Debasish Mishra (Texas A&M University) for his generous contributions to the content of this resource over the years."
  },
  {
    "objectID": "ch1.html#operators-and-data-types",
    "href": "ch1.html#operators-and-data-types",
    "title": "2  Basics of R",
    "section": "2.1 Operators and data types",
    "text": "2.1 Operators and data types\n\n2.1.1 Basic operators\nIn this section, we will learn about some basic R operators that are used to perform operations on variables. Some most commonly used operators are shown in the table below.\n\n\n\n\nR follows the conventional order (sequence) to solve mathematical operations, abbreviated as BODMAS: Brackets, Orders (exponents), Division, Multiplication, Addition, and Subtraction\n\n\n2+4+7 # Sum\n\n[1] 13\n\n4-5   # Subtraction\n\n[1] -1\n\n2*3   # Multiplication\n\n[1] 6\n\n1/2   # Division\n\n[1] 0.5\n\n# Order of operation\n1/2*3+4-5\n\n[1] 0.5\n\n1/2*(3+4-5)\n\n[1] 1\n\n1/(2*(3+4-5))\n\n[1] 0.25\n\n1/(2*3+4-5) \n\n[1] 0.2\n\n# Notice how output changes with the placement of operators\n\n# Other operators:\n2^3\n\n[1] 8\n\nlog(10)\n\n[1] 2.302585\n\nsqrt(4)\n\n[1] 2\n\npi\n\n[1] 3.141593\n\n# Clear the Environment\nrm(list=ls()) # rm is for remove,ls is short for list. The empty parenthesis i.e. () signifies all content. \n\n\n\n2.1.2 Basic data operations\nIn this section, we will create some vector data and apply built-in operations to examine the properties of a dataset.\n\n# The \"is equal to\" or \"assignment operator in R is \"&lt;-\" or \"=\" \n\n# Generate sample data. Remember \"c\" comes from for \"concatenate\". \ndata&lt;-c(1,4,2,3,9)    # Try data = c(1,4,2,3,9). Is there any difference in data in both cases?\n\n# rbind combines data by rows, and hence \"r\"bind\n# cbind combines data by columns, and hence \"c\"bind\n\n# Checking the properties of a dataset. Note: the na.rm argument ignores NA values in the dataset.\ndata=rbind(1,4,2,3,9) \ndim(data)           # [5,1]: 5 rows, 1 column\n\n[1] 5 1\n\ndata[2,1]           # Show the value in row 2, column 1\n\n[1] 4\n\ndata[c(2:5),1]      # Show a range of values in column 1\n\n[1] 4 2 3 9\n\nmean(data, na.rm=T) # Mean\n\n[1] 3.8\n\nmax(data)           # Maximum\n\n[1] 9\n\nmin(data)           # Minimum\n\n[1] 1\n\nsd(data)            # Standard deviation\n\n[1] 3.114482\n\nvar(data)           # Variance\n\n     [,1]\n[1,]  9.7\n\nsummary(data) \n\n       V1     \n Min.   :1.0  \n 1st Qu.:2.0  \n Median :3.0  \n Mean   :3.8  \n 3rd Qu.:4.0  \n Max.   :9.0  \n\nstr(data)        # Prints structure of data\n\n num [1:5, 1] 1 4 2 3 9\n\nhead(data)       # Returns the 1st 6 items in the object\n\n     [,1]\n[1,]    1\n[2,]    4\n[3,]    2\n[4,]    3\n[5,]    9\n\nhead(data, 2)    # Print first 2\n\n     [,1]\n[1,]    1\n[2,]    4\n\ntail(data, 2)    # Print last 2\n\n     [,1]\n[4,]    3\n[5,]    9\n\n# Do the same, but with \"c()\" instead of \"rbind\"\ndata=c(1,4,2,3,9) \ndim(data)        # Note: dim is NULL\n\nNULL\n\nlength(data)     # Length of a dataset is the number of variables (columns)\n\n[1] 5\n\ndata[2]          # This should give you 4 \n\n[1] 4\n\n# Other operators work in the same way\nmean(data)       # Mean\n\n[1] 3.8\n\nmax(data)        # Maximum\n\n[1] 9\n\nmin(data)        # Minimum\n\n[1] 1\n\nsd(data)         # Standard deviation\n\n[1] 3.114482\n\nvar(data)        # Variance\n\n[1] 9.7\n\n# Text data\ndata=c(\"LSU\",\"SPESS\",\"AgCenter\",\"Tigers\") \ndata             # View\n\n[1] \"LSU\"      \"SPESS\"    \"AgCenter\" \"Tigers\"  \n\ndata[1]\n\n[1] \"LSU\"\n\n# Mixed data\ndata=c(1,\"LSU\",10,\"AgCenter\") # All data is treated as text if one value is text\ndata[3]                       # Note how output is in quotes i.e. \"10\"\n\n[1] \"10\"\n\n\n\nFor help with a function in R, just type ? followed by the function to display information in the help menu. Try pasting ?sd in the console.\n\n\n\n2.1.3 Data types\nIn R, data is stored as an “array”, which can be 1-dimensional or 2-dimensional. A 1-D array is called a “vector” and a 2-D array is a “matrix”. A table in R is called a “data frame” and a “list” is a container to hold a variety of data types. In this section, we will learn how to create matrices, lists and data frames in R.\n\n\n\n\n# Lets make a random matrix\ntest_mat = matrix( c(2, 4, 3, 1, 5, 7), # The data elements \n  nrow=2,         # Number of rows \n  ncol=3,         # Number of columns \n  byrow = TRUE)   # Fill matrix by rows \n\ntest_mat = matrix( c(2, 4, 3, 1, 5, 7),nrow=2,ncol=3,byrow = TRUE) # Same result \ntest_mat\n\n     [,1] [,2] [,3]\n[1,]    2    4    3\n[2,]    1    5    7\n\ntest_mat[,2]      # Display all rows, and second column\n\n[1] 4 5\n\ntest_mat[2,]      # Display second row, all columns\n\n[1] 1 5 7\n\n# Types of datasets\nout = as.matrix(test_mat)\nout               # This is a matrix\n\n     [,1] [,2] [,3]\n[1,]    2    4    3\n[2,]    1    5    7\n\nout = as.array(test_mat)\nout               # This is also a matrix\n\n     [,1] [,2] [,3]\n[1,]    2    4    3\n[2,]    1    5    7\n\nout = as.vector(test_mat)\nout               # This is just a vector\n\n[1] 2 1 4 5 3 7\n\n# Data frame and list\ndata1=runif(50,20,30) # Create 50 random numbers between 20 and 30  \ndata2=runif(50,0,10)  # Create 50 random numbers between 0 and 10  \n\n# Lists\nout = list()        # Create and empty list\nout[[1]] = data1    # Notice the brackets \"[[ ]]\" instead of \"[ ]\"\nout[[2]] = data2\nout[[1]]          # Contains data1 at this location\n\n [1] 26.68965 22.47674 27.47109 21.33879 20.99883 24.26102 27.09342 26.19098\n [9] 29.04661 27.11492 24.28314 20.23793 22.88767 26.78536 20.54715 26.88795\n[17] 29.93076 29.80179 20.34742 23.41408 22.23048 22.76696 28.39182 26.33096\n[25] 23.61659 25.37934 26.12018 28.05096 24.33298 26.60576 28.41264 22.02089\n[33] 29.94938 26.47782 26.02164 28.23036 23.92716 27.97650 28.45764 23.36751\n[41] 20.88730 22.91508 21.49197 29.67451 29.94210 26.24338 23.38382 28.45715\n[49] 23.60752 25.01958\n\n# Data frame\nout=data.frame(x=data1, y=data2)\n\n# Let's see how it looks!\nplot(out$x, out$y)\n\n\n\nplot(out[,1])\n\n\n\n\n\nFor a data frame, the dollar “$” sign invokes the variable selection. Imagine how one would receive merchandise in a store if you give $ to the cashier. Data frame will list out the variable names for you of you when you show it some $."
  },
  {
    "objectID": "ch1.html#plotting-with-base-r",
    "href": "ch1.html#plotting-with-base-r",
    "title": "2  Basics of R",
    "section": "2.2 Plotting with base R",
    "text": "2.2 Plotting with base R\nIf you need to quickly visualize your data, base R has some functions that will help you do this in a pinch. In this section we’ll look at some basics of visualizing univariate and multivariate data.\n\n2.2.1 Overview\n\n# Create 50 random numbers between 0 and 100  \ndata=runif(50, 0, 100)   #runif stands for random numbers from a uniform distribution\n\n# Let's plot the data\nplot(data)            # The \"plot\" function initializes the plot.\n\n\n\nplot(data, type=\"l\")  # The \"type\" argument changes the plot type. \"l\" calls up a line plot\n\n\n\nplot(data, type=\"b\")  # Buffered points joined by lines\n\n\n\n# Try options type = \"o\" and type = \"c\" as well.\n\n# We can also quickly visualize boxplots, histograms, and density plots using the same procedure\nboxplot(data)        # Box-and-whisker plot\n\n\n\nhist(data)           # Histogram points\n\n\n\nplot(density(data))  # Plot with density distribution \n\n\n\n\n\n\n2.2.2 Plotting univariate data\nLet’s dig deeper into the plot function. Here, we will look at how to adjust the colors, shapes, and sizes for markers, axis labels and titles, and the plot title.\n\n# Line plots\nplot(data,type=\"o\", col=\"red\",\n     xlab=\"x-axis title\",ylab =\"y-axis title\", \n     main=\"My plot\", # Name of axis labels and title\n     cex.axis=2, cex.main=2,cex.lab=2,            # Size of axes, title and label\n     pch=23,       # Change marker style\n     bg=\"red\",     # Change color of markers\n     lty=5,        # Change line style\n     lwd=2         # Selecting line width\n) \n# Adding legend\nlegend(1, 100, legend=c(\"Data 1\"),\n       col=c(\"red\"), lty=2, cex=1.2)\n\n\n\n# Histograms\nhist(data,col=\"red\",\n     xlab=\"Number\",ylab =\"Value\", main=\"My plot\", # Name of axis labels and title\n     border=\"blue\"\n) \n\n\n\n# Try adjusting the parameters:\n# hist(data,col=\"red\",\n#      xlab=\"Number\",ylab =\"Value\", main=\"My plot\", # Name of axis labels and title\n#      cex.axis=2, cex.main=2,cex.lab=2,            # Size of axes, title and label\n#      border=\"blue\", \n#      xlim=c(0,100), # Control the limits of the x-axis\n#      las=0,      # Try different values of las: 0,1,2,3 to rotate labels\n#      breaks=5    # Try using 5,20,50, 100\n# ) # Using more options and controls\n\n\n\n2.2.3 Plotting multivariate data\nHere, we introduce you to data frames: equivalent of tables in R. A data frame is a table with a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column.\n\nplot_data=data.frame(x=runif(50,0,10), \n                     y=runif(50,20,30), \n                     z=runif(50,30,40)) \n\nplot(plot_data$x, plot_data$y) # Scatter plot of x and y data\n\n\n\n# Mandatory beautification\nplot(plot_data$x,plot_data$y, xlab=\"Data X\", ylab=\"Data Y\", main=\"X vs Y plot\",\n     col=\"darkred\",pch=20,cex=1.5) # Scatter plot of x and y data\n\n\n\n# Multiple lines on one axis\nmatplot(plot_data, type = c(\"b\"),pch=16,col = 1:4) \n\n\n\nmatplot(plot_data, type = c(\"b\",\"l\",\"o\"),pch=16,col = 1:4) # Try this now. Any difference? \nlegend(\"topleft\", legend = 1:4, col=1:4, pch=1)            # Add legend to a top left\nlegend(\"top\", legend = 1:4, col=1:4, pch=1)                # Add legend to at top center\nlegend(\"bottomright\", legend = 1:4, col=1:4, pch=1)        # Add legend at the bottom right\n\n\n\n\n\n\n2.2.4 Time series data\nWorking with time series data can be tricky at first, but here’s a quick look at how to quickly generate a time series using the as.Date function.\n\ndate=seq(as.Date('2011-01-01'),as.Date('2011-01-31'),by = 1) # Generate a sequence 31 days\ndata=runif(31,0,10)                 # Generate 31 random values between 0 and 10\ndf=data.frame(Date=date,Value=data) # Combine the data in a data frame\nplot(df,type=\"o\")\n\n\n\n\n\n\n2.2.5 Combining plots\nYou can built plots that contain subplots. Using base R, we call start by using the “par” function and then plot as we saw before.\n\npar(mfrow=c(2,2)) # Call a plot with 4 quadrants\n\n# Plot 1\nmatplot(plot_data, type = c(\"b\"),pch=16,col = 1:4) \n\n# Plot 2\nplot(plot_data$x,plot_data$y) \n\n# Plot 3\nhist(data,col=\"red\",\n     xlab=\"Number\",ylab =\"Value\", main=\"My plot\", \n     border=\"blue\") \n\n# Plot4\nplot(data,type=\"o\", col=\"red\",\n     xlab=\"Number\",ylab =\"Value\", main=\"My plot\",\n     cex.axis=2, cex.main=2,cex.lab=2, \n     pch=23,   \n     bg=\"red\", \n     lty=5, \n     lwd=2 \n) \n\n\n\n# Alternatively, we can call up a plot using a matrix\nmatrix(c(1,1,2,3), 2, 2, byrow = TRUE) # Plot 1 is plotted for first two spots, followed by plot 2 and 3 \n\n     [,1] [,2]\n[1,]    1    1\n[2,]    2    3\n\nlayout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE)) # Fixes a layout of the plots we want to make\n\n # Plot 1\nmatplot(plot_data, type = c(\"b\"),pch=16,col = 1:4)\n\n# Plot2\nplot(plot_data$x,plot_data$y) \n\n# Plot 3\nhist(data,col=\"red\",\n     xlab=\"Number\",ylab =\"Value\", main=\"My plot\",\n     border=\"blue\"\n)\n\n\n\n\n\n\n2.2.6 Saving figures to disk\nPlots can be saved as image files or a PDF. This is done by specifying the output file type, its size and resolution, then calling the plot.\n\npng(\"awesome_plot.png\", width=4, height=4, units=\"in\", res=400) \n#Tells R we will plot image in png of given specification\n\nmatplot(plot_data, type = c(\"b\",\"l\",\"o\"),pch=16,col = 1:4)  \nlegend(\"topleft\", legend = 1:4, col=1:4, pch=1)\n\ndev.off() # Very important: this sends the image to disc\n\npng \n  2 \n\n# Keep pressing till you get the following: \n# Error in dev.off() : cannot shut down device 1 (the null device) \n# This ensures that we are no longer plotting.\n\n# It looks like what everything we just plotted was squeezed together to tightly. Let's change the size.\npng(\"awesome_plot.png\", width=6, height=4, units=\"in\", res=400)  #note change in dimension\n#Tells R we will plot image in png of given specification\n\nmatplot(plot_data, type = c(\"b\",\"l\",\"o\"),pch=16,col = 1:3)  \nlegend(\"topleft\", legend = 1:3, col=1:3, pch=16)\n\ndev.off() \n\npng \n  2 \n\n\n\nSome useful resources\nIf you want to plot something a certain way and don’t know how to do it, the chances are that someone has asked that question before. Try a Google search for what your are trying to do and check out some of the forums. There is TONS of material online. Here are some additional resources:\n\nThe R Graph Gallery: https://www.r-graph-gallery.com/\nGraphical parameters: https://www.statmethods.net/advgraphs/parameters.html\nPlotting in R: https://www.harding.edu/fmccown/r/\nHistogram: https://www.r-bloggers.com/how-to-make-a-histogram-with-basic-r/"
  },
  {
    "objectID": "ch1.html#plotting-with-ggplot2",
    "href": "ch1.html#plotting-with-ggplot2",
    "title": "2  Basics of R",
    "section": "2.3 Plotting with ggplot2",
    "text": "2.3 Plotting with ggplot2\n\n2.3.1 Import libraries and create sample dataset\nFor this section, we will use the ggplot2, gridExtra, utils, and tidyr packages. gridExtra and cowplot are used to combine ggplot objects into one plot and utils and tidyr are useful for manipulating and reshaping the data. We will also install some packages here that will be required for the later sections. You will find more information in the sections to follow.\n\n###############################################################\n#~~~ Load required libraries\nlib_names=c(\"ggplot2\",\"gridExtra\",\"utils\",\"tidyr\",\"cowplot\", \"RColorBrewer\")\n\n# If you see a prompt: Do you want to restart R prior to installing: Select **No**. \n\n# Install all necessary packages (Run once)\n# invisible(suppressMessages\n#           (suppressWarnings\n#             (lapply\n#               (lib_names,install.packages,repos=\"http://cran.r-project.org\",\n#                 character.only = T))))\n\n# Load necessary packages\ninvisible(suppressMessages\n          (suppressWarnings\n            (lapply\n              (lib_names,library, character.only = T))))\n\nIn more day-to-day use, you will see yourself using a simpler version of these commands, such as, if you were to install the “ggplot2”,“gridExtra” libraries, you will type:\n\n# To install the package. Install only once\ninstall.packages(\"ggplot2\")\n# To initialize the package. Invoke every time a new session begins.\nlibrary(ggplot2)\n\nSimilarly, again for gridExtra ,\n\ninstall.packages(\"gridExtra\")\nlibrary(gridExtra)\n\nFor this exercise, let us generate a sample dataset.\n\n###############################################################\n#~~~ Generate a dataset containing random numbers within specified ranges\nYear = seq(1913,2001,1)\nJan = runif(89, -18.4, -3.2)\nFeb = runif(89, -19.4, -1.2)\nMar = runif(89, -14, -1.8)\nJanuary = runif(89, 1, 86)\ndat = data.frame(Year, Jan, Feb, Mar, January)\n\n\n\n2.3.2 Basics of ggplot\nWhereas base R has an “ink on paper” plotting paradigm, ggplot has a “grammar of graphics” paradigm that packages together a variety plotting functions. With ggplot, you assign the result of a function to an object name and then modify it by adding additional functions. Think of it as adding layers using pre-designed functions rather than having to build those functions yourself, as you would have to do with base R.\n\nl1 = ggplot(data=dat, aes(x = Year, y = Jan, color = \"blue\")) + # Tell which data to plot\n  geom_line() +      # Add a line\n  geom_point() +     # Add a points\n  xlab(\"Year\") +     # Add labels to the axes\n  ylab(\"Value\")\n\n# Or, they can be specified for any individual geometry\nl1 + geom_line(linetype = \"solid\", color=\"Blue\")  # Add a solid line\n\n\n\nl1 + geom_line(aes(x = Year, y = January)) # Add a different data set\n\n\n\n# There are tons of other built-in color scales and themes, such as scale_color_grey(), scale_color_brewer(), theme_classic(), theme_minimal(), and theme_dark()\n\n# OR, CREATE YOUR OWN THEME! You can group themes together in one list\ntheme1 = theme(\n  legend.position = \"none\",\n  panel.background = element_blank(),\n  plot.title = element_text(hjust = 0.5),\n  axis.line = element_line(color = \"black\"),\n  axis.text.y   = element_text(size = 11),\n  axis.text.x   = element_text(size = 11),\n  axis.title.y  = element_text(size = 11),\n  axis.title.x  = element_text(size = 11),\n  panel.border = element_rect(\n    colour = \"black\",\n    fill = NA,\n    size = 0.5\n  )\n)\n\n\n\n2.3.3 Multivariate plots\nFor multivariate data, ggplot takes the data in the form of groups. This means that each data row should be identifiable to a group. To get the most out of ggplot, we will need to reshape our dataset.\n\nlibrary(tidyr)\n\n# There are two generally data formats: wide (horizontal) and long (vertical). In the horizontal format, every column represents a category of the data. In the vertical format, every row represents an observation for a particular category (think of each row as a data point). Both formats have their comparative advantages. We will now convert the data frame we randomly generated in the previous section to the long format. Here are several ways to do this:\n\n# Using the gather function (the operator %&gt;% is called pipe operator)\ndat2 = dat %&gt;% gather(Month, Value, -Year)\n\n# This is equivalent to: \ndat2 = gather(data=dat, Month, Value, -Year)\n\n# Using pivot_longer and selecting all of the columns we want. This function is the best!\ndat2 = dat %&gt;% pivot_longer(cols = c(Jan, Feb, Mar), names_to = \"Month\", values_to = \"Value\") \n\n# Or we can choose to exclude the columns we don't want\ndat2 = dat %&gt;% pivot_longer(cols = -c(Year,January), names_to = \"Month\", values_to = \"Value\") \n\nhead(dat2) # The data is now shaped in the long format\n\n# A tibble: 6 × 4\n   Year January Month  Value\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1  1913    70.5 Jan    -4.60\n2  1913    70.5 Feb    -7.79\n3  1913    70.5 Mar   -11.7 \n4  1914    23.9 Jan    -6.20\n5  1914    23.9 Feb   -17.5 \n6  1914    23.9 Mar   -11.9 \n\n\nLine plot\n\n# LINE PLOT\nl = ggplot(dat2, aes(x = Year, y = Value, group = Month)) +\n  geom_line(aes(color = Month)) +\n  geom_point(aes(color = Month))\nl\n\n\n\n\nDensity plot\n\n# DENSITY PLOT\nd = ggplot(dat2, aes(x = Value))\nd = d + geom_density(aes(color = Month, fill = Month), alpha=0.4) # Alpha specifies transparency\nd\n\n\n\n\nHistogram\n\n# HISTOGRAM\nh = ggplot(dat2, aes(x = Value))\nh = h + geom_histogram(aes(color = Month, fill = Month), alpha=0.4,\n                 fill = \"white\",\n                 position = \"dodge\")\nh\n\n\n\n\nGrid plotting and saving files to disk\nThere are multiple ways to arrange multiple plots and save images. One method is using grid.arrange() which is found in the gridExtra package. You can then save the file using ggsave, which comes with the ggplot2 library.\n\n# The plots can be displayed together on one image using \n# grid.arrange from the gridExtra package\nimg = grid.arrange(l, d, h, nrow=3)\n\n\n\n# Finally, plots created using ggplot can be saved using ggsave\nggsave(\"grid_plot_1.png\", \n       plot = img, \n       device = \"png\", \n       width = 6, \n       height = 4, \n       units = c(\"in\"), \n       dpi = 600)\n\nAnother approach is to use the plot_grid function, which is in the cowplot library. Notice how the axes are now beautifally aligned.\n\nimg2=cowplot::plot_grid(l, d, h, nrow = 3, align = \"v\") # \"v\" aligns vertical axes and \"h\" aligns horizontal axes\n\nggsave(\"grid_plot_2.png\", \n       plot = img2, \n       device = \"png\", \n       width = 6, \n       height = 4, \n       units = c(\"in\"), \n       dpi = 600)\n\n\n\n2.3.4 Using patchwork for combining ggplots\nPatchwork works with simple operators to combine plots. The operator | arranges plots in a row. The plus sign + does the same but it will try to wrap the plots symmetrically as a square whenever possible. The division i.e. /operator layers a plot on top of another.\n\n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\nl+d\n\n\n\nl/ (h+d)\n\n\n\n# Try: l/d/h or (l+d)/h \n\n# Make your own design for arranging plots (the # sign means empty space): \ndesign &lt;- \"\n  111\n  2#3\n\"\nl + d + h + plot_layout(design = design)\n\n\n\n\n\nSome useful resources\nThe links below offer a treasure trove of examples and sample code to get you started.\n\nThe R Graph Gallery: https://www.r-graph-gallery.com/\nR charts: https://r-charts.com/\nExcellent resource for combining multiple ggplots: https://r-charts.com/ggplot2/combining-plots/"
  },
  {
    "objectID": "ch1.html#exercise-1",
    "href": "ch1.html#exercise-1",
    "title": "2  Basics of R",
    "section": "2.4 Exercise #1",
    "text": "2.4 Exercise #1\nThe U.S. Climate Reference Network (USCRN) is a systematic and sustained network of climate monitoring stations. USCRN has sites across Contiguous U.S. along with some in Alaska, and Hawaii. These stations are instrumented to measure meteorological information such as temperature, precipitation, wind speed, along with other relevant hydrologic variables such as soil moisture at uniform depths (5, 10, 20, 50, 100 cm) at sub-hourly, daily and monthly time scales. Users can access daily data set from all station suing the following link: Index of /pub/data/uscrn/products/daily01 (noaa.gov)\nLet us extract sample data from a USCRN site in Lafayette, LA, USA for 2021.\n\n# Yearly data from the sample station\nCRNdat = read.csv(url(\"https://www.ncei.noaa.gov/pub/data/uscrn/products/daily01/2021/CRND0103-2021-LA_Lafayette_13_SE.txt\"), header=FALSE,sep=\"\")\n\n# Data headers\nheaders=read.csv(url(\"https://www.ncei.noaa.gov/pub/data/uscrn/products/daily01/headers.txt\"), header=FALSE,sep=\"\")\n\n# Column names as headers from the text file\ncolnames(CRNdat)=headers[2,1:ncol(CRNdat)]\n\n# Replace fill values with NA\nCRNdat[CRNdat == -9999]=NA\nCRNdat[CRNdat == -99]=NA\nCRNdat[CRNdat == 999]=NA\n\n# View data sample\nlibrary(kableExtra)\ndataTable = kbl(head(CRNdat,6),full_width = F)\nkable_styling(dataTable,bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\n\nWBANNO\nLST_DATE\nCRX_VN\nLONGITUDE\nLATITUDE\nT_DAILY_MAX\nT_DAILY_MIN\nT_DAILY_MEAN\nT_DAILY_AVG\nP_DAILY_CALC\nSOLARAD_DAILY\nSUR_TEMP_DAILY_TYPE\nSUR_TEMP_DAILY_MAX\nSUR_TEMP_DAILY_MIN\nSUR_TEMP_DAILY_AVG\nRH_DAILY_MAX\nRH_DAILY_MIN\nRH_DAILY_AVG\nSOIL_MOISTURE_5_DAILY\nSOIL_MOISTURE_10_DAILY\nSOIL_MOISTURE_20_DAILY\nSOIL_MOISTURE_50_DAILY\nSOIL_MOISTURE_100_DAILY\nSOIL_TEMP_5_DAILY\nSOIL_TEMP_10_DAILY\nSOIL_TEMP_20_DAILY\nSOIL_TEMP_50_DAILY\nSOIL_TEMP_100_DAILY\n\n\n\n\n53960\n20210101\n2.622\n-91.87\n30.09\n14.0\n5.2\n9.6\n11.0\n0.0\n12.16\nC\n18.7\n4.6\n11.6\n92.8\n49.3\n72.0\n0.401\n0.372\n0.380\n0.405\n0.381\n16.2\n15.3\n15.5\n15.7\n15.5\n\n\n53960\n20210102\n2.622\n-91.87\n30.09\n10.4\n1.9\n6.1\n6.5\n0.0\n8.95\nC\n15.3\n0.4\n7.3\n98.6\n61.6\n78.4\n0.396\n0.370\n0.377\n0.406\n0.376\n14.4\n13.3\n14.1\n15.2\n15.0\n\n\n53960\n20210103\n2.622\n-91.87\n30.09\n16.3\n-0.1\n8.1\n7.9\n0.0\n13.93\nC\n24.3\n-0.9\n9.5\n100.0\n42.1\n76.3\n0.392\n0.368\n0.374\n0.404\n0.373\n12.8\n11.8\n12.8\n14.4\n14.2\n\n\n53960\n20210104\n2.622\n-91.87\n30.09\n22.2\n3.7\n12.9\n12.5\n0.0\n11.56\nC\n26.4\n2.6\n13.2\n98.9\n47.7\n80.2\n0.389\n0.366\n0.370\n0.400\n0.372\n13.0\n12.2\n12.7\n14.0\n14.0\n\n\n53960\n20210105\n2.622\n-91.87\n30.09\n20.7\n4.5\n12.6\n11.4\n0.0\n14.37\nC\n28.9\n3.1\n13.3\n100.0\n27.7\n71.0\n0.388\n0.364\n0.368\n0.399\n0.369\n13.0\n12.1\n12.7\n13.9\n14.0\n\n\n53960\n20210106\n2.622\n-91.87\n30.09\n19.4\n4.9\n12.2\n12.6\n20.7\n9.79\nC\n23.1\n3.5\n12.8\n98.5\n54.7\n78.9\n0.390\n0.363\n0.369\n0.399\n0.370\n12.8\n12.1\n12.5\n13.7\n13.7\n\n\n\n\n\n\n\n\nNotice the variables provided in the dataset. As an example, we can plots soil moisture data from a depth of 20 cm for this station for our reference:\n\n# Sample plot for soil moisture\nx=CRNdat$SOIL_MOISTURE_20_DAILY\n\n# Plot time series and density distribution \nplot(x, type=\"l\", ylab=\"Soil moisture (v/v)\", \n     col=\"cyan4\", lwd=3)\nplot(density(na.omit(x)), main=\" \", xlab=\"\", \n     col=\"cyan4\", lwd=3)\n\n\n\n\n\n\n\n(a) Time series of SM\n\n\n\n\n\n\n\n(b) SM kernel density\n\n\n\n\nFigure 2.1: Soil moisture values at the selected USCRN station\n\n\n\nExercise:\n\nTaking examples of any two USCRN stations across contrasting hydroclimates, compare and contrast any two recorded variables using time series plots, probability density distribution histograms and scatter plots. Select any year of your liking for the analysis.\nSelect two seasons for each elected variable and demonstrate the seasonal variability in the records for summer (MAMJJA) and winter (SONDJF) seasons using any two types of multivariate plots.\n[EXTRA]: For any chosen station, plot a time-series of soil moisture from all available layers with precipitation added as an inverted secondary axis. For inspiration, see Figure 4 in Cheng, et al. 2021. On change of soil moisture distribution with vegetation reconstruction in Mu Us sandy land of China, with newly designed lysimeter. Frontiers in Plant Science, 12, p.60952 at https://www.frontiersin.org/articles/10.3389/fpls.2021.609529/full"
  },
  {
    "objectID": "ch2.html#overview",
    "href": "ch2.html#overview",
    "title": "3  Spatial Mapping in R",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nIn this chapter we will learn about different types of spatial datasets (raster and vector). We will visualize these spatial datasets using static and interactive plotting options available in R. We will also explore different color palettes options available for generating spatial maps for scientific/technical reporting of spatial datasets. We will also learn briefly explore coordinate reference systems and map projections for spatial data representation.\n\n3.1.1 Sample dataset\nWe will familiarize ourselves with several open-source global datasets and use them to practice spatial mapping and computing in R.\n\n\n\n\nGlobal surface soil moisture from NASA’s Soil Moisture Active Passive (SMAP) satellite (Entekhabi, Njoku, and O’Neill 2009)\n\nhttps://smap.jpl.nasa.gov/\n\n\n\n\nNormalized Difference Vegetation Index (NDVI) from Moderate Resolution Imaging Spectroradiometer (MODIS) (Huete, Justice, and Van Leeuwen 1999)\n\nhttps://modis.gsfc.nasa.gov/data/dataprod/mod13.php\n\n\n\n\nGlobal climate reference land regions from Coupled Model Intercomparison Project (CMIP) project (Iturbide et al. 2020)\n\nhttps://essd.copernicus.org/articles/12/2959/2020/\n\n\n\n\nClimate classification (Hyper-arid, arid, semi-arid, sub-humid and humid) based on Global Aridity Index Database (Zomer, Xu, and Trabucco 2022)\n\nhttps://csidotinfo.wordpress.com/2019/01/24/global-aridity-index-and-potential-evapotranspiration-climate-database-v3/\n\n\n\n\n\n\n3.1.2 Data download\nThe sample dataset for this resource is uploaded to GitHub for easy access. Download the sample data manually as a zip file from: https://github.com/Vinit-Sehgal/SampleData . Once downloaded, extract the zip folder to the current working directory.\nAlternatively, use the following script to programmatically download and extract the sample data from the GitHub repository.\n\n###############################################################\n#~~~ Import sample data from GitHub repository\n\nif (dir.exists(\"SampleData-master\")==FALSE){ \n# First we check if the folder already exists. If not, the download begins\ndownload.file(url = \"https://github.com/Vinit-Sehgal/SampleData/archive/master.zip\",\ndestfile = \"SampleData-master.zip\")    # Download \".Zip\"\n\n# Unzip the downloaded .zip file\nunzip(zipfile = \"SampleData-master.zip\")\n}\n\n# getwd()                           # Current working directory\nlist.files(\"./SampleData-master\")   # List folder contents. Do you see sample datasets?\n\n [1] \"CMIP_land\"                               \n [2] \"functions\"                               \n [3] \"images\"                                  \n [4] \"Largescale_geospatial_analysis_2022.html\"\n [5] \"Largescale_geospatial_analysis_2023.html\"\n [6] \"location_points.xlsx\"                    \n [7] \"ne_10m_coastline\"                        \n [8] \"raster_files\"                            \n [9] \"README.md\"                               \n[10] \"sample_pdfs\"                             \n[11] \"SMAP_L3_USA.nc\"                          \n[12] \"SMAPL4_H5\"                               \n[13] \"SMOS_nc\"                                 \n[14] \"USA_states\"                              \n[15] \"Workbook_DVGAR21-Part1.html\"             \n[16] \"Workbook_DVGAR21-Part2.html\""
  },
  {
    "objectID": "ch2.html#using-r-as-gis",
    "href": "ch2.html#using-r-as-gis",
    "title": "3  Spatial Mapping in R",
    "section": "3.2 Using R as GIS",
    "text": "3.2 Using R as GIS\nA geographic information system, or GIS refers to a platform which can map, analyzes and manipulate geographically referenced dataset. A geographically referenced data (or geo-referenced data) is a spatial dataset which can be related to a point on Earth with the help of geographic coordinates. Types of geo-referenced spatial data include: rasters (grids of regularly sized pixels) and vectors (polygons, lines, points).\n\n\n\n\n\nA quick and helpful review of spatial data can be found here: https://spatialvision.com.au/blog-raster-and-vector-data-in-gis/\n\n3.2.1 Plotting raster data: with terra and tmap\nIn this section, we plot global raster data of surface (~5 cm) soil moisture from SMAP. Let’s start by first importing the global soil moisture raster.\n# Import package for raster operations\nlibrary(terra) \n\n# Import SMAP soil moisture raster from the downloaded folder\nsm=terra::rast(\"./SampleData-master/raster_files/SMAP_SM.tif\")\nOnce we have imported the SpatRaster (short for “spatial raster”) using rast() function from terra package, let’s note its attributes. Notice the dimensions, resolution, extent, crs i.e. coordinate reference system and values. Note that the cell of one raster layer can only hold a single numerical value.\n# Print raster attributes\nprint(sm)\nclass : SpatRaster dimensions : 456, 964, 1 (nrow, ncol, nlyr) resolution : 0.373444, 0.373444 (x, y) extent : -180, 180, -85.24595, 85.0445 (xmin, xmax, ymin, ymax) coord. ref. : lon/lat WGS 84 (EPSG:4326) source : SMAP_SM.tif name : SMAP_SM min value : 0.01999998 max value : 0.87667608\n# Try:\n# dim(sm)   # Dimension (nrow, ncol, nlyr) of the raster\n# terra::res(sm)   # X-Y resolution of the raster\n# terra::ext(sm)   # Spatial extent of the raster\n# terra::crs(sm)   # Coordinate reference system\nNow let’s plot the raster using terra::plot.\n# Basic Raster plot \nterra::plot(sm, main = \"Soil Moisture\") \n\n\n\n3.2.2 Color palettes\nUsing a good color palette is an important aspect of spatial mapping. Choice of a good colormap can help the readers understand the key aspects of the map. The selected colors must adequately represent the key features and their differences, wherever applicable, with the least distortion, ambiguity or effort. There are several libraries available in R specifically dedicated to generating color pelettes for scientific mapping. We will also learn the the usage of cetcolor and scico packages to generate perceptually uniform and color-blindness friendly palettes.\n\nSome key packages for generating color palettes for scientific mapping are:\n\nRColorBrewer: https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3\ncetcolors (Perceptually Uniform Colour Maps): https://cran.r-project.org/web/packages/cetcolor/vignettes/cet_color_schemes.html\nscico (Scientific colormaps): https://github.com/thomasp85/scico\n\n\n# Libraries for generating Colour palettes\nlibrary(RColorBrewer)\nlibrary(cetcolor)\nlibrary(scico)\n\n# To view color palette \nlibrary(unikn)   \n\n#~~ A) User defined color palette using brewer.pal\nmypal1 = RColorBrewer::brewer.pal(10, \"Spectral\") \n\n# Brewerpal outputs a max of 9-11 colors. So,the pelette may needs expansion.\nmypal2= colorRampPalette(mypal1)(20)         # Expand pelette to 20 colors\nunikn::seecol(mypal2)   \n\n\n\n# Some more advanced options include opacity and interpolation method \n# mypal2= colorRampPalette(mypal1,                         \n#                interpolate = c(\"linear\"), # Choose btw linear/spline interpolation\n#                alpha = 0.8)(20)           # Generate 20 colors, opacity set to 0.8\n# unikn::seecol(mypal2)   \n\n#~~ B) User defined color palette using scico package\nmypal1 = scico::scico(20, alpha = 1.0, direction =  -1, palette = \"vik\") \nunikn::seecol(mypal1)   \n\n\n\n#Check: scico_palette_names() for available palettes! \n# Try combinations of alpha=0.5, direction =1, and various different color palette  \n\n#~~ C) User defined color palette using cetcolor package\nmypal2 = cetcolor::cet_pal(20, name = \"r2\")   \nunikn::seecol(mypal2)  \n\n\n\n# Or reverse color pal \nmypal2 = rev(cetcolor::cet_pal(20, name = \"r2\") )  \nunikn::seecol(mypal2) \n\n\n\n\n\n\n3.2.3 Customizing terra plot options\nThere is a long list of customization operations available while plotting rasters in R.\nWe will start with basic plot from terra, and then explore the function by changing different customization options , such as: Try horizontal=TRUE, interpolate=FALSE, change xlim=c(-180, 180) with asp=1, or try legend.shrink=0.4.\n\nsm=rast(\"./SampleData-master/raster_files/SMAP_SM.tif\") # SMAP soil moisture data\n\nterra::plot(sm,\n            main = \"Scientific Plot of Raster\",\n            \n            #Color options\n            col = mypal2,                    # User Defined Color Palette\n            breaks = seq(0, 1, by=0.1),      # Sequence from 0-1 with 0.1 increment\n            colNA = \"lightgray\",             # Color of cells with NA values\n            \n            # Axis options      \n            axes=TRUE,                       # Plot axes: TRUE/ FALSE\n            xlim=c(-180, 180),               # X-axis limit\n            ylim=c(-90, 90),                 # Y-axis limit\n            xlab=\"Longitude\",                # X-axis label\n            ylab=\"Latitue\",                  # Y-axis label\n            \n            # Legend options      \n            legend=TRUE,                     # Plot legend: TRUE/ FALSE\n            \n            # Miscellaneous\n            mar = c(3.1, 3.1, 2.1, 7.1),     # Margins\n            grid = FALSE                     # Add grid lines\n        )\n\n\n\n\n\n\n3.2.4 Spatial plotting with tmap\n\nlibrary(tmap)\n# Set tmap mode: Static plot=\"plot\", Interactive plots=\"view\"\ntmap_mode(\"plot\")          \n\ntmap_SM = tm_shape(sm)+\n  tm_grid(alpha = 0.2)+                             # Transparency of grid\n  tm_raster(alpha = 0.7,                            # Transparency of raster plot\n            palette = mypal2,                       # Color pellete\n            style = \"pretty\",                       # Select style\n            title = \"Volumetric Soil Moisture\")+    # Plot main title\n  tm_layout(legend.position = \n              c(\"left\", \"bottom\"))+                 # Placement of legend\n  tm_xlab(\"Longitude\")+                             # x-lab\n  tm_ylab(\"Latitude\")                               # y-lab \n\ntmap_SM\n\n\n\n\n\n\n3.2.5 Interactive raster visualization aster data with mapview\nFunctionality of terra is largely similar to the legacy package raster (created by the same developer, Robert Hijmans). The development of terra is inspired by computational efficiency in geospatial operations. However, since terra is relatively new, and is continually developed, several other packages require conversion of the SpatRasters to rasterLayer for backwards compatibility.\nTo convert a SpatRaster to RasterLayer, use: sm2=as(sm, \"Raster\")\n\nlibrary(mapview)\nlibrary(raster)\n\n# Convert SpatRaster to raster (from package raster)\nsm2=as(sm, \"Raster\")\nmapview(sm2,                  # RasterLayer\n        col.regions = mypal2, # Color palette \n        at=seq(0, 0.8, 0.1)   # Breaks\n)\n\n\n\n\n\n\n\n3.2.6 Plotting raster data using tidyterra\ntidyterra is a package that add common methods from the tidyverse for SpatRaster and SpatVectors objects created with the terra package. It also adds specific geom_spat*() functions for plotting rasters with ggplot2.\nNote on Performance: tidyterra is conceived as a user-friendly wrapper of terra using the tidyverse} methods and verbs. This approach therefore has a cost in terms of performance.\n\nlibrary(tidyterra) \nlibrary(ggplot2)  \nggplot() +   \n  geom_spatraster(data = sm) +   \n  scale_fill_gradientn(colors=mypal2,                 # Use user-defined colormap\n         name = \"SM\",                                 #  Name of the colorbar\n         na.value = \"transparent\",                    # transparent NA cells  \n         labels=(c(\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\")), # Labels of colorbar\n         breaks=seq(0,0.8,by=0.2),                    # Set breaks of colorbar\n         limits=c(0,0.8))+   \n    theme_void()  # Try other themes: theme_bw(), theme_gray(), theme_minimal() \n\n\n\n\nWhat if we are interested in a particular region and not the entire globe? We can plot the map for a specific extent (CONUS, in this case) by changing the range of coord_sfoption. We will also use a different theme: theme_bw. Try xlim = c(114,153) and ylim = c(-43,-11)! We will also add state boundaries and coastline to the plot.\n\nsm_conus= ggplot() +\n  geom_spatraster(data = sm) +\n  scale_fill_gradientn(colors=mypal2,                               # User-defined colormap\n                       name = \"SM\",                                 # Name of the colorbar\n                       na.value = \"transparent\",                    # transparent NA cells\n                       labels=(c(\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\")), # Labels of colorbar\n                       breaks=seq(0,0.8,by=0.2),                    # Set breaks of colorbar\n                       limits=c(0,0.8)) +\n  coord_sf(xlim = c(-125,-67),                                      # Add extent for CONUS\n           ylim = c(24,50))+               \n  borders(\"world\",                              # Add global landmass boundaries\n          colour=\"gray43\",                      # Fill light-gray color to the landmass\n          fill=\"transparent\")+                  # Transparent background\n  borders(\"state\",                              # Add US state borders\n          colour=\"gray43\",                      # Use light-gray color\n          fill=\"transparent\")+                  # Use transparent background  \n  theme_bw()                                    # Black & white theme \n\nprint(sm_conus)\n\n\n\n\n\n\n3.2.7 Plotting vector data\nImporting and plotting shapefiles is equally easy in R. We will import the shapefile of the updated global IPCC climate reference regions and global coastlineas Simple Feature (sf) Object. Terra can also be used to import shapefiles as vectors using the function vect. However, sf is more versatile, especially for shapefiles. Notice how the attributes of the sf objects resemble an Excel data sheet.\n\nlibrary(sf)  \nlibrary(terra)\n\n##~~~~ Use sf package for shapefile \n# Import the shapefile of global IPCC climate reference regions (only for land) \nIPCC_shp = read_sf(\"./SampleData-master/CMIP_land/CMIP_land.shp\")\n# View attribute table of the shapefile\nIPCC_shp # Notice the attributes look like a data frame\n\nSimple feature collection with 41 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -168 ymin: -56 xmax: 180 ymax: 85\nGeodetic CRS:  WGS 84\n# A tibble: 41 × 5\n   V1              V2                V3       V4                        geometry\n   &lt;chr&gt;           &lt;chr&gt;             &lt;chr&gt; &lt;dbl&gt;                   &lt;POLYGON [°]&gt;\n 1 ARCTIC          Greenland/Iceland GIC       1 ((-10 58, -10.43956 58, -10.87…\n 2 NORTH-AMERICA   N.E.Canada        NEC       2 ((-55 50, -55.4386 50, -55.877…\n 3 NORTH-AMERICA   C.North-America   CNA       3 ((-90 50, -90 49.5614, -90 49.…\n 4 NORTH-AMERICA   E.North-America   ENA       4 ((-70 25, -70.43478 25, -70.86…\n 5 NORTH-AMERICA   N.W.North-America NWN       5 ((-105 50, -105.4386 50, -105.…\n 6 NORTH-AMERICA   W.North-America   WNA       6 ((-130 50, -129.5614 50, -129.…\n 7 CENTRAL-AMERICA N.Central-America NCA       7 ((-90 25, -90.37179 24.76923, …\n 8 CENTRAL-AMERICA S.Central-America SCA       8 ((-75 12, -75.28 11.67333, -75…\n 9 CENTRAL-AMERICA Caribbean         CAR       9 ((-75 12, -75.32609 12.28261, …\n10 SOUTH-AMERICA   N.W.South-America NWS      10 ((-75 12, -74.57143 12, -74.14…\n# ℹ 31 more rows\n\n##~~~~ Use terra package for shapefile \nIPCC_shp = vect(\"./SampleData-master/CMIP_land/CMIP_land.shp\")\n# IPCC_shp\n\n# Load global coastline shapefile \ncoastlines = read_sf(\"./SampleData-master/ne_10m_coastline/ne_10m_coastline.shp\")\n\n# Alternatively, download global coastlines from the web \n# NOTE: May not work if the online server is down\n# download.file(\"https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/physical/ne_110m_coastline.zip?version=4.0.1\",destfile = 'ne_110m_coastline.zip')\n# # Unzip the downloaded file\n# unzip(zipfile = \"ne_110m_coastline.zip\",exdir = 'ne-coastlines-110m')\n\nSubsetting vector data is similar to selecting a row from a data frame.\n\nENA_poly=IPCC_shp[4,] # Subset shapefile for Eastern North-America (ENA) \nENA_poly              # Polygon contents - notice it has 4 attributes\n\n class       : SpatVector \n geometry    : polygons \n dimensions  : 1, 4  (geometries, attributes)\n extent      : -90, -55, 25, 50  (xmin, xmax, ymin, ymax)\n coord. ref. : lon/lat WGS 84 (EPSG:4326) \n names       :            V1              V2    V3    V4\n type        :         &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n values      : NORTH-AMERICA E.North-America   ENA     4\n\n# Plot ENA polygon using terra\nterra::plot(ENA_poly, main=\"Polygon for Eastern North-America\")  \n\n\n\n\nLet us see how to combine rasters with overlapping vectors with terra . Remember to execute the lines with add=TRUE with the base plot.\n\nterra::plot(sm, col=mypal2)\nterra::plot(IPCC_shp, add=TRUE, col=\"transparent\", border = \"black\")\nterra::plot(coastlines, add=TRUE, col=\"transparent\", border = \"black\")\n\n\n\n\nLets mark the location of Baton Rouge on this map. We will first make a base plot, over which coastlines and spatial location will be added. Again, remember to run these lines together.\n\n#~~~ Add spatial point to shapefile/ raster\n#~~ Make base map\nterra::plot(IPCC_shp[c(3,4,6,7),], # IPCC land regions for Contiguous US.\n             col = \"lightgray\",     # Background color\n             border = \"black\")      # Border color\n\n#~~ Add coastline\nterra::plot(coastlines, col= \"maroon\", add=TRUE)  \n\n#~~ Add spatial point to the plot\nLong=-91.0; Lat=30.62                  # Lat- Long of Baton Rouge, LA\npoints(cbind(Long,Lat),                # Lat-Long as Spatial Points\n       col=\"blue\", pch=16, cex=1.2)    # Shape, size and color of point\n\n\n\n\n\n\n3.2.8 Reprojection of rasters using terra::project\nA coordinate reference system (CRS) is used to relate locations on Earth (which is a 3-D spheroid) to a 2-D projected map using coordinates (for example latitude and longitude). Projected CRSs are usually expressed in Easting and Northing (x and y) values corresponding to long-lat values in Geographic CRS.\nA good description of coordinate reference systems and their importance can be found here:\n\nhttps://docs.qgis.org/3.4/en/docs/gentle_gis_introduction/coordinate_reference_systems.html\nhttps://datacarpentry.org/organization-geospatial/03-crs/\n\n\n\n\n\n\nIn R, the coordinate reference systems or CRS are commonly specified in EPSG (European Petroleum Survey Group) or PROJ4 format (See: https://epsg.io/). Few commonly used projection systems and their codes are summarized below:\n\n\n\n\n\n\n\n\n\nProjection system\nPROJ.4 code\nEPSG code\n\n\nNAD83 (North American Datum 1983)\n“+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs +type=crs”\nEPSG:4269\n\n\nMercator\n“+proj=merc +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +R=6371000 +units=m +no_defs +type=crs”\nESRI:53004\n\n\nWGS 84 (World Geodetic System 1984)\n“+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs”\nEPSG:3395\n\n\nWGS 84 / Pseudo-Mercator – Spherical Mercator ( used in Google Maps, OpenStreetMap)\n“+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs +type=crs” |\nEPSG:3857\n\n\nRobinson (better for plotting global data due to minimal distortion, except for higher latitudes)\n“+proj=robin +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs”\nESRI:54030\n\n\n\n\nThe SpatRaster reprojection process is done with project() from the terra package.\n# Importing SMAP soil moisture data\nsm=rast(\"./SampleData-master/raster_files/SMAP_SM.tif\") \n\n#~~ Projection 1: NAD83 (EPSG: 4269)\n\nsm_proj1 = terra::project(sm, \"epsg:4269\")\n\nterra::plot(sm_proj1, \n             main = \"NAD83\",    # Title of the plot\n             col = mypal2,      # Colormap for the plot\n             axes = FALSE,      # Disable axes\n             box = FALSE,       # Disable box around the plots\n             asp = NA,          # No fixed aspect ratio; asp=NA fills plot to window\n             legend=FALSE)      # Disable legend\n\n#~~ Projection 2: World Robinson projection (ESRI:54030)\n\nsm_proj2 = terra::project(sm, \"ESRI:54030\")\n\nterra::plot(sm_proj2, \n             main = \"Robinson\", # Title of the plot\n             col = mypal2,      # Colormap for the plot\n             axes = FALSE,      # Disable axes\n             box = FALSE,       # Disable box around the plots\n             asp = NA,          # No fixed aspect ratio; asp=NA fills plot to window\n             legend=FALSE)      # Disable legend\n\nLet us now plot a map of global surface soil moisture, reprojected to Robinson projection. Notice that to add the raster and vector to the plot, we use the functions geom_spatraster and geom_spatvector respectively. Another package spData provides several important datasets for global mapping, including, US states polygons (us_states), World country polygons (world), global elevation (elev.tif), among others (https://jakubnowosad.com/spData/). We will use orld country polygons (world) in our map.\n\nlibrary(spData)\n# Import global political boundaries from spData package\nWorldSHP=terra::vect(spData::world)             \n\n# Generate plot\nRobinsonPlot &lt;- ggplot() +\n  geom_spatraster(data = sm)+                   # Plot SpatRaster layer               \n  geom_spatvector(data = WorldSHP, \n                  fill = \"transparent\") +       # Add world political map\n  ggtitle(\"Robinson Projection\") +              # Add title\n  scale_fill_gradientn(colors=mypal2,           # Use user-defined colormap\n                       name = \"Soil Moisture\",  # Name of the colorbar\n                       na.value = \"transparent\",# Set color for NA values\n                       lim=c(0,0.8))+           # Z axis limit\n  theme_minimal()+                              # Select theme. Try 'theme_void'\n  theme(plot.title = element_text(hjust =0.5),  # Place title in the middle of the plot\n        text = element_text(size = 12))+        # Adjust plot text size for visibility\n  coord_sf(crs = \"ESRI:54030\",                  # Reproject to World Robinson\n           xlim = c(-152,152)*100000,           # Convert x-y limits from decimal Deg. to meter\n           ylim = c(-55,90)*100000)\n\nprint(RobinsonPlot)\n\n\n\n# Save high resolution plot to disk\n  # ggsave(\n  #   \"globalSM.png\",          # Name of the file to be created\n  #   plot = RobinsonPlot,     # Plot to be exported\n  #   bg = \"white\",            # Plot background\n  #   height = 6,              # Height \n  #   width = 10,              # Width  \n  #   units = c(\"in\")          # Units (\"in\", \"cm\", \"mm\" or \"px\")\n  # )\n\nRun the commented script above, and view the exported plot saved on the disk.\nOther resources:\n\nMore excellent examples on making maps in R can be found here: https://bookdown.org/nicohahn/making_maps_with_r5/docs/introduction.html.\nQuintessential resource for reference on charts and plots in R: https://www.r-graph-gallery.com/index.html.\n\n\n\n\n\nEntekhabi, Dara, Eni Njoku, and Peggy O’Neill. 2009. “The Soil Moisture Active and Passive Mission (SMAP): Science and Applications.” 2009 IEEE Radar Conference. https://doi.org/10.1109/radar.2009.4977030.\n\n\nHuete, Alfredo, Chris Justice, and Wim Van Leeuwen. 1999. “MODIS Vegetation Index (MOD13).” Algorithm Theoretical Basis Document 3 (213): 295–309.\n\n\nIturbide, Maialen, José M. Gutiérrez, Lincoln M. Alves, Joaquín Bedia, Ruth Cerezo-Mota, Ezequiel Cimadevilla, Antonio S. Cofiño, et al. 2020. “An Update of IPCC Climate Reference Regions for Subcontinental Analysis of Climate Model Data: Definition and Aggregated Datasets.” Earth System Science Data 12 (4): 2959–70. https://doi.org/10.5194/essd-12-2959-2020.\n\n\nZomer, Robert J, Jianchu Xu, and Antonio Trabucco. 2022. “Version 3 of the Global Aridity Index and Potential Evapotranspiration Database.” Scientific Data 9 (1): 409."
  },
  {
    "objectID": "ch3.html#raster-resampling",
    "href": "ch3.html#raster-resampling",
    "title": "4  Geospatial operations on raster and vectors",
    "section": "4.1 Raster Resampling",
    "text": "4.1 Raster Resampling\nRaster resampling refers to changing the resolution of the raster. The term “resampling” used here implies that the pixel values are “sampled” to the new resolution using an interpolation method (nearest neighbor, bilinear, spline, min, max, mode, average etc). We will try three important functions for changing the resolution of a SpatRaster: terra::aggregate (resample from fine to coarse resolution), terra::disagg (resample from coarse to fine resolution) and terra::resample (resample to match the resolution of another raster). The following schematic helps illustrate the use of these functions:\n\nLets us now explore an example for raster resampling.\n\nlibrary(terra)\n\n# Import SMAP soil moisture raster\nsm=terra::rast(\"./SampleData-master/raster_files/SMAP_SM.tif\") \n\n# Original resolution of raster for reference\nres(sm)\n\n[1] 0.373444 0.373444\n\n#~~ Aggregate raster to coarser resolution\nSMcoarse = terra::aggregate(sm,           # Soil moisture raster\n                            fact = 10,    # Aggregate by x 10\n                            fun = mean)   # Function used to aggregate values\nres(SMcoarse)\n\n[1] 3.73444 3.73444\n\n#~~ Disaggregate raster to finer resolution\nSMfine = terra::disagg(sm, \n                   fact=3, \n                   method='bilinear')\nres(SMfine)\n\n[1] 0.1244813 0.1244813\n\n#~~ Raster resampling\n# Import global aridity raster\naridity=rast(\"./SampleData-master/raster_files/aridity_36km.tif\") \n\n# Plot aridity map\nmypal = RColorBrewer::brewer.pal(5, \"Spectral\") \nterra::plot(aridity, col=mypal, main= \"Aridity Spatraster\")\n\n\n\n# Resample aridity raster to coarse resolution  \naridityResamp=terra::resample(aridity,      # Original raster\n                       SMcoarse,            # Target resolution raster\n                       method='ngb')        # bilinear or ngb (nearest neighbor) \n\n# Plot resampled aridity map\nterra::plot(aridityResamp, col=mypal, main= \"Aridity at Coarser Resolution\")"
  },
  {
    "objectID": "ch3.html#raster-summary-statistics",
    "href": "ch3.html#raster-summary-statistics",
    "title": "4  Geospatial operations on raster and vectors",
    "section": "4.2 Raster Summary Statistics",
    "text": "4.2 Raster Summary Statistics\nArithmetic operations a.k.a. arith-generic (+, -, *, /, ^, %%, %/%) on SpatRasters closely resemble simple vector-like operations. More details on arith-generic can be found here: https://rdrr.io/cran/terra/man/arith-generic.html.  We will use global function to apply summary statistics and user-defined operations on cells of a raster.\n\n# Simple arithmetic operations\nsm2=sm*2\nprint(sm2) # Try sm2=sm*10, or sm2=sm^2 and see the difference in sm2 values\n\nclass       : SpatRaster \ndimensions  : 456, 964, 1  (nrow, ncol, nlyr)\nresolution  : 0.373444, 0.373444  (x, y)\nextent      : -180, 180, -85.24595, 85.0445  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nvarname     : SMAP_SM \nname        :    SMAP_SM \nmin value   : 0.03999996 \nmax value   : 1.75335217 \n\n# Summary statistics\nglobal(sm, mean, na.rm = T)\n\n            mean\nSMAP_SM 0.209402\n\nglobal(sm, sd, na.rm = T)\n\n               sd\nSMAP_SM 0.1434444\n\nglobal(sm, quantile, probs = c(0.25, 0.75), na.rm = T)\n\n              X25.      X75.\nSMAP_SM 0.09521707 0.2922016\n\n# User-defined statistics by defining own function\nquant_fun = function(x, na.rm=TRUE){ # Remember to add \"na.rm\" option\n  quantile(x, probs = c(0.25, 0.75), na.rm=TRUE)\n} \nglobal(sm, quant_fun)   # 25th, and 75th percentile of each layer\n\n              X25.      X75.\nSMAP_SM 0.09521707 0.2922016\n\n\n\nNote: With a multi-layered raster object, global will summarize each layer separately.\n\n\n4.2.1 Raster Summary with Polygons\nLet’s explore using a spatial polygon/shapefile for summarizing a raster (in this case, global SMAP soil moisture) by using extract function from the terra library. We will also transform global aridity raster to a polygon using as.polygons and st_as_sf functions to find the mean soil moisture values for each aridity class.\nFirst, we will use the IPCC shapefile to summarize the soil moisture raster.\n\n# Import the shapefile of global IPCC climate reference regions (only for land) \nIPCC_shp = vect(\"./SampleData-master/CMIP_land/CMIP_land.shp\")\n\n#~~~ Using shapefile to summarize a raster\nsm_IPCC_df=terra::extract(sm,        # Spatraster to be summarized\n                          IPCC_shp,   # Shapefile/ polygon to summarize the raster\n                          #df=TRUE,   # Gives the summary statistics as a dataframe\n                          fun=mean,   # Desired statistic: mean, sum, min and max \n                          na.rm=TRUE) # Ignore NA values? TRUE=yes! \n\nhead(sm_IPCC_df)\n\n  ID   SMAP_SM\n1  1 0.2545766\n2  2 0.3839087\n3  3 0.2345457\n4  4 0.3788003\n5  5 0.2383580\n6  6 0.1475145\n\n#~~~ Extract cell values for each region \nsm_IPCC_list=terra::extract(sm,       # Raster to be summarized\n                          IPCC_shp,   # Shapefile/ polygon to summarize the raster\n                          df=FALSE,   # Returns a list\n                          fun=NULL,   # fun=NULL will output cell values within each region\n                          na.rm=TRUE) # Ignore NA values? yes! \n\n# Apply function on cell values for each region\nsm_IPCC_mean=lapply(sm_IPCC_list,mean)                       # Returns a list of regional means \nsm_IPCC_mean=purrr::map(sm_IPCC_list,~ mean(.x, na.rm=TRUE)) # Returns a list of regional means\n\n#~~ Try user defined function\nmyfun=function (y){return(mean(y, na.rm=TRUE))}    # User defined function for calculating means\n\n#~ Implement function using lapply and map\nlibrary(purrr)\n\nsm_IPCC_mean=lapply(sm_IPCC_list,myfun)           # Returns a list of regional means \nsm_IPCC_mean=purrr::map(sm_IPCC_list,~ myfun(.x)) # Returns a list of regional means \nsm_IPCC_mean=unlist(sm_IPCC_mean)                 # Unlist to return a vector \n\nhead(sm_IPCC_mean) # Is this the same as the previous result?\n\n        ID    SMAP_SM \n21.1513647  0.2088026 \n\n\n\n\n4.2.2 Raster Summary with Classified Raster\nIn the next example, we will convert global aridity raster into a polygon based on aridity classification using as.polygons and st_as_sf functions.  Global aridity raster has 5 classes with 5 indicating humid and 1 indicating hyper-arid climate. We will use this polygon to extract values from the Spatraster and summarize soil moisture for each aridity class.\n\n#~~~ Convert a raster to a shapefile\naridity=rast(\"./SampleData-master/raster_files/aridity_36km.tif\") #Global aridity\n\n# Convert raster to shapefile\narid_poly=as.polygons(aridity)   # Convert SpatRaster to polygon and then to sf\n\n# Plot aridity polygon\nterra::plot(arid_poly, \n     col=arid_poly$aridity_36km)  # Colors based on aridity values (i.e. 1,2,3,4,5)\n\n\n\n\nSummarize values of SMAP soil moisture raster for aridity classes:\n\nsm_arid_df=terra::extract(sm,        # Raster to be summarized\n                          arid_poly, # Shapefile/ polygon to summarize the raster\n                          #df=TRUE,   # Gives the summary statistics as a dataframe\n                          fun=mean,  # Desired statistic: mean, sum, min and max \n                          na.rm=TRUE)# Ignore NA values? yes! \n\n# Lets plot the climate-wise mean of surface soil moisture\n{plot(sm_arid_df,     \n     xaxt = \"n\",              # Disable x-tick labels\n     xlab=\"Aridity\",          # X axis label\n     ylab=\"Soil moisture\",    # Y axis label\n     type=\"b\",                # line type\n     col=\"blue\",              # Line color\n     main=\"Climate-wise mean of surface soil moisture\")\naxis(1, at=1:5, labels=c(\"Hyper-arid\", \"Arid\", \"Semi-Arid\",\"Sub-humid\",\"Humid\"))}"
  },
  {
    "objectID": "chN.html",
    "href": "chN.html",
    "title": "5  References",
    "section": "",
    "text": "References\n\n\n\nEntekhabi, Dara, Eni Njoku, and Peggy O’Neill. 2009. “The Soil\nMoisture Active and Passive Mission (SMAP): Science and\nApplications.” 2009 IEEE Radar Conference. https://doi.org/10.1109/radar.2009.4977030.\n\n\nHuete, Alfredo, Chris Justice, and Wim Van Leeuwen. 1999. “MODIS\nVegetation Index (MOD13).” Algorithm Theoretical Basis\nDocument 3 (213): 295–309.\n\n\nIturbide, Maialen, José M. Gutiérrez, Lincoln M. Alves, Joaquín Bedia,\nRuth Cerezo-Mota, Ezequiel Cimadevilla, Antonio S. Cofiño, et al. 2020.\n“An Update of IPCC Climate Reference Regions for Subcontinental\nAnalysis of Climate Model Data: Definition and Aggregated\nDatasets.” Earth System Science Data 12 (4): 2959–70. https://doi.org/10.5194/essd-12-2959-2020.\n\n\nZomer, Robert J, Jianchu Xu, and Antonio Trabucco. 2022. “Version\n3 of the Global Aridity Index and Potential Evapotranspiration\nDatabase.” Scientific Data 9 (1): 409."
  }
]